{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook makes all the features for both the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df_test = pd.read_csv('../data/interim/test_cleaned.csv',index_col=False)\n",
    "df_train = pd.read_csv('../data/interim/train_cleaned.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make Panda Series covert into log scale\n",
    "def feature_log(df,col):\n",
    "    df['Log'+col] = np.log1p(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = feature_log(df_train,'SalePrice')\n",
    "df_train = feature_log(df_train,'Gr Liv Area')\n",
    "df_test = feature_log(df_test,'Gr Liv Area')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['MS SubClass'] = df_train['MS SubClass'].apply(lambda x: str(x))\n",
    "df_test['MS SubClass'] = df_test['MS SubClass'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train['Gr Liv Area'] < 4000) & (df_train['LogSalePrice'] > 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Input: Pass in a custom ordered dictionary and the column names you want to apply to the dateframe.\n",
    "Output: Trasformed dataframe\n",
    "'''\n",
    "def feature_ordinal_custom(ordered_dict,column_list,df):\n",
    "    for col in column_list:\n",
    "        df[col] = df[col].map(ordered_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make order numeric values for quality\n",
    "ordered_rating_qual = { \"0\": 0, \"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n",
    "\n",
    "# Not all of them but only a select few columns I want to convert\n",
    "qual_list = ['Exter Qual',\n",
    "             'Exter Cond',\n",
    "             'Bsmt Qual',\n",
    "             'Kitchen Qual',\n",
    "             'Fireplace Qu',\n",
    "             'Garage Qual'\n",
    "            ]\n",
    "# Apply to dataframes\n",
    "df_train = feature_ordinal_custom(ordered_rating_qual,qual_list,df_train)\n",
    "df_test = feature_ordinal_custom(ordered_rating_qual,qual_list,df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: Dataframe and list of columns to apply dummy\n",
    "Output: \n",
    "'''\n",
    "def feature_make_dummies(df,dummy_list):\n",
    "    # Create dummies on dataset\n",
    "    for col in dummy_list:\n",
    "        dummy = pd.get_dummies(df[col], columns=col, prefix=col)\n",
    "        df = pd.concat([df, dummy], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup dummies on short list, doing all will not be helpful\n",
    "dummy_list = ['MS Zoning',\n",
    "              'MS SubClass',\n",
    "              'Neighborhood',\n",
    "              'Bldg Type',\n",
    "              'House Style',\n",
    "              'Roof Style',\n",
    "              'Exterior 1st',\n",
    "              'Exterior 2nd',\n",
    "              'Foundation',\n",
    "              'Functional',\n",
    "              'Garage Type',\n",
    "              'Garage Finish',\n",
    "              'Paved Drive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that doing get dummies on the test set will short change us on the columns so lets prep for that\n",
    "# DNR AGAIN\n",
    "for col in dummy_list:\n",
    "    df_test[col] = df_test[col].fillna(\"None\")\n",
    "    test_values = sorted(list(df_test[col].unique()))\n",
    "    train_values = sorted(list(df_train[col].unique()))\n",
    "    categories = set(train_values + test_values)\n",
    "    df_test[col] = pd.Categorical(df_test[col], categories=categories)\n",
    "    df_train[col] = pd.Categorical(df_train[col], categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = feature_make_dummies(df_train,dummy_list)\n",
    "df_test = feature_make_dummies(df_test,dummy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2045, 213)\n",
      "(879, 213)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Age of Remodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Age of Remodel'] = df_train['Yr Sold']-df_train['Year Remod/Add']\n",
    "df_test['Age of Remodel'] = df_test['Yr Sold']-df_test['Year Remod/Add']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Total Baths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Total Bath'] = df_train['Full Bath'] + df_train['Bsmt Full Bath'] + (df_train['Half Bath'] + df_train['Bsmt Half Bath'])/2\n",
    "df_test['Total Bath'] = df_test['Full Bath'] + df_test['Bsmt Full Bath'] + (df_test['Half Bath'] + df_test['Bsmt Half Bath'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Total Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sum Qual'] = df_train['Exter Qual'] + df_train['Bsmt Qual'] + df_train['Kitchen Qual'] + df_train['Fireplace Qu'] + df_train['Garage Qual']\n",
    "df_test['Sum Qual'] = df_test['Exter Qual'] + df_test['Bsmt Qual'] + df_test['Kitchen Qual'] + df_test['Fireplace Qu'] + df_test['Garage Qual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate which values to Scale\n",
    "num_discrete_col = df_train.select_dtypes('uint8').columns.tolist()\n",
    "num_conti_col = df_train.drop(['SalePrice', 'LogSalePrice'], axis=1).select_dtypes(['float64','int64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "ss = StandardScaler() # Instantiate Standard Scaler\n",
    "ss.fit(pd.concat([df_train[num_conti_col],df_test[num_conti_col]]))\n",
    "df_train[num_conti_col] = ss.transform(df_train[num_conti_col]) \n",
    "df_test[num_conti_col] = ss.transform(df_test[num_conti_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrices\n",
    "num_columns = list(df_train._get_numeric_data().drop(['SalePrice', 'LogSalePrice'], axis=1).columns)\n",
    "cat_columns = list(df_train.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in num_columns:\n",
    "    df_test[feature] = df_test[feature].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('../data/processed/test_scaled2.csv')\n",
    "df_train.to_csv('../data/processed/train_scaled2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
